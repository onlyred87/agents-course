# ì†ë‹˜ ìŠ¤í† ë¦¬ë¥¼ ìœ„í•œ RAG ë„êµ¬ ë§Œë“¤ê¸°

ì—¬ëŸ¬ë¶„ì˜ ì‹ ë¢°ë°›ëŠ” ì—ì´ì „íŠ¸ AlfredëŠ” ì„¸ê¸°ì˜ ê°€ì¥ í™”ë ¤í•œ ê°ˆë¼ íŒŒí‹°ë¥¼ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤. í–‰ì‚¬ê°€ ì›í™œí•˜ê²Œ ì§„í–‰ë˜ê¸° ìœ„í•´ AlfredëŠ” ê° ì†ë‹˜ì— ëŒ€í•œ ìµœì‹  ì •ë³´ë¥¼ ì‹ ì†í•˜ê²Œ í™•ì¸í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ë§ì¶¤í˜• ë°ì´í„°ì…‹ì„ í™œìš©í•œ Retrieval-Augmented Generation(RAG) ë„êµ¬ë¥¼ ë§Œë“¤ì–´ Alfredë¥¼ ë„ì™€ë´…ì‹œë‹¤.

## ì™œ ê°ˆë¼ íŒŒí‹°ì— RAGê°€ í•„ìš”í• ê¹Œìš”?

Alfredê°€ ì†ë‹˜ë“¤ ì‚¬ì´ë¥¼ ì˜¤ê°€ë©°, ì¦‰ì„ì—ì„œ ê° ì¸ë¬¼ì— ëŒ€í•œ ì„¸ë¶€ ì •ë³´ë¥¼ ê¸°ì–µí•´ì•¼ í•œë‹¤ê³  ìƒìƒí•´ë³´ì„¸ìš”. ê¸°ì¡´ LLMë§Œìœ¼ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ë¡œ ì´ ì‘ì—…ì´ ì–´ë µìŠµë‹ˆë‹¤:

1. ì†ë‹˜ ëª…ë‹¨ì€ ì—¬ëŸ¬ë¶„ì˜ í–‰ì‚¬ì—ë§Œ í•´ë‹¹ë˜ë©°, ëª¨ë¸ì˜ í•™ìŠµ ë°ì´í„°ì— í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤
2. ì†ë‹˜ ì •ë³´ê°€ ìì£¼ ë³€ê²½ë˜ê±°ë‚˜ ì—…ë°ì´íŠ¸ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤
3. AlfredëŠ” ì´ë©”ì¼ ì£¼ì†Œ ë“± ì •í™•í•œ ì„¸ë¶€ ì •ë³´ë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤

ì´ëŸ´ ë•Œ Retrieval Augmented Generation(RAG)ì´ ë¹›ì„ ë°œí•©ë‹ˆë‹¤! ê²€ìƒ‰ ì‹œìŠ¤í…œê³¼ LLMì„ ê²°í•©í•˜ë©´, AlfredëŠ” ì†ë‹˜ì— ëŒ€í•œ ì •í™•í•˜ê³  ìµœì‹  ì •ë³´ë¥¼ í•„ìš”í•  ë•Œë§ˆë‹¤ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<Tip>
ì´ ì‚¬ë¡€ì—ì„œëŠ” ë³¸ ê³¼ì •ì—ì„œ ë‹¤ë£¬ ì–´ë–¤ í”„ë ˆì„ì›Œí¬ë„ ììœ ë¡­ê²Œ ì„ íƒí•´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì½”ë“œ íƒ­ì—ì„œ ì›í•˜ëŠ” ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”.
</Tip>

## ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì„±í•˜ê¸°

ì´ë²ˆ ìœ ë‹›ì—ì„œëŠ” HF Space ë‚´ì—ì„œ êµ¬ì¡°í™”ëœ Python í”„ë¡œì íŠ¸ë¡œ ì—ì´ì „íŠ¸ë¥¼ ê°œë°œí•©ë‹ˆë‹¤. ì´ ë°©ì‹ì€ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ë³„ë„ íŒŒì¼ë¡œ ë¶„ë¦¬í•´ ê¹”ë”í•˜ê³  ëª¨ë“ˆí™”ëœ ì½”ë“œë¥¼ ìœ ì§€í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. ë˜í•œ ì‹¤ì œë¡œ ê³µê°œ ë°°í¬í•˜ëŠ” í˜„ì‹¤ì ì¸ ì‚¬ë¡€ì™€ë„ ì˜ ë§ìŠµë‹ˆë‹¤.

### í”„ë¡œì íŠ¸ êµ¬ì¡°

- **`tools.py`** â€“ ì—ì´ì „íŠ¸ìš© ë³´ì¡° ë„êµ¬ ì œê³µ
- **`retriever.py`** â€“ ì§€ì‹ ì ‘ê·¼ì„ ìœ„í•œ ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„
- **`app.py`** â€“ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•´ ì™„ì „í•œ ì—ì´ì „íŠ¸ë¡œ ì™„ì„±(ìœ ë‹› ë§ˆì§€ë§‰ì— ì™„ì„±)

ì‹¤ìŠµ ì˜ˆì‹œë¡œ, ì´ ìœ ë‹›ì—ì„œ ê°œë°œí•œ Agentic RAGê°€ ì‹¤ì œë¡œ ë™ì‘í•˜ëŠ” [ì´ HF Space](https://huggingface.co/spaces/agents-course/Unit_3_Agentic_RAG)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”. í´ë¡ í•´ì„œ ì§ì ‘ ì‹¤í—˜í•´ë³¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤!

ì•„ë˜ì—ì„œ ì—ì´ì „íŠ¸ë¥¼ ì§ì ‘ í…ŒìŠ¤íŠ¸í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

<iframe
	src="https://agents-course-unit-3-agentic-rag.hf.space"
	frameborder="0"
	width="850"
	height="450"
></iframe>

## ë°ì´í„°ì…‹ ê°œìš”

ìš°ë¦¬ì˜ ë°ì´í„°ì…‹ [`agents-course/unit3-invitees`](https://huggingface.co/datasets/agents-course/unit3-invitees/)ì—ëŠ” ê° ì†ë‹˜ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì€ í•„ë“œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

- **ì´ë¦„(Name)**: ì†ë‹˜ì˜ ì „ì²´ ì´ë¦„
- **ê´€ê³„(Relation)**: ì†ë‹˜ê³¼ í˜¸ìŠ¤íŠ¸ì˜ ê´€ê³„
- **ì„¤ëª…(Description)**: ì†ë‹˜ì— ëŒ€í•œ ê°„ë‹¨í•œ ì†Œê°œ ë˜ëŠ” í¥ë¯¸ë¡œìš´ ì‚¬ì‹¤
- **ì´ë©”ì¼ ì£¼ì†Œ(Email Address)**: ì´ˆëŒ€ì¥ ë°œì†¡ì´ë‚˜ í›„ì† ì—°ë½ì„ ìœ„í•œ ì •ë³´

ì•„ë˜ëŠ” ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸°ì…ë‹ˆë‹¤:
<iframe
  src="https://huggingface.co/datasets/agents-course/unit3-invitees/embed/viewer/default/train"
  frameborder="0"
  width="100%"
  height="560px"
></iframe>

<Tip>
ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì´ ë°ì´í„°ì…‹ì— ì‹ë‹¨ ì„ í˜¸, ì„ ë¬¼ ê´€ì‹¬ì‚¬, í”¼í•´ì•¼ í•  ëŒ€í™” ì£¼ì œ ë“± í˜¸ìŠ¤íŠ¸ì—ê²Œ ìœ ìš©í•œ ë‹¤ì–‘í•œ ì •ë³´ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
</Tip>

## ì†ë‹˜ë¶€(RAG) ë„êµ¬ ë§Œë“¤ê¸°

Alfredê°€ ê°ˆë¼ íŒŒí‹° ì¤‘ ì†ë‹˜ ì •ë³´ë¥¼ ì‹ ì†í•˜ê²Œ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ë§ì¶¤í˜• ë„êµ¬ë¥¼ ë§Œë“¤ì–´ë´…ì‹œë‹¤. ì„¸ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì§„í–‰í•©ë‹ˆë‹¤:

1. ë°ì´í„°ì…‹ ë¡œë“œ ë° ì¤€ë¹„
2. ê²€ìƒ‰(Retriever) ë„êµ¬ ìƒì„±
3. ë„êµ¬ë¥¼ Alfredì™€ í†µí•©

ë¨¼ì € ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ì¤€ë¹„í•˜ëŠ” ê²ƒë¶€í„° ì‹œì‘í•©ì‹œë‹¤!

### 1ë‹¨ê³„: ë°ì´í„°ì…‹ ë¡œë“œ ë° ì¤€ë¹„

ë¨¼ì €, ì›ì‹œ ì†ë‹˜ ë°ì´í„°ë¥¼ ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

Hugging Face `datasets` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³ , `langchain.docstore.document` ëª¨ë“ˆì˜ `Document` ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```python
import datasets
from langchain.docstore.document import Document

# ë°ì´í„°ì…‹ ë¡œë“œ
guest_dataset = datasets.load_dataset("agents-course/unit3-invitees", split="train")

# ê° ì†ë‹˜ í•­ëª©ì„ Document ê°ì²´ë¡œ ë³€í™˜
docs = [
    Document(
        page_content="\n".join([
            f"Name: {guest['name']}",
            f"Relation: {guest['relation']}",
            f"Description: {guest['description']}",
            f"Email: {guest['email']}"
        ]),
        metadata={"name": guest["name"]}
    )
    for guest in guest_dataset
]

```

</hfoption>
<hfoption id="llama-index">

Hugging Face `datasets` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³ , `llama_index.core.schema` ëª¨ë“ˆì˜ `Document` ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```python
import datasets
from llama_index.core.schema import Document

# ë°ì´í„°ì…‹ ë¡œë“œ
guest_dataset = datasets.load_dataset("agents-course/unit3-invitees", split="train")

# ê° ì†ë‹˜ í•­ëª©ì„ Document ê°ì²´ë¡œ ë³€í™˜
docs = [
    Document(
        text="\n".join([
            f"Name: {guest_dataset['name'][i]}",
            f"Relation: {guest_dataset['relation'][i]}",
            f"Description: {guest_dataset['description'][i]}",
            f"Email: {guest_dataset['email'][i]}"
        ]),
        metadata={"name": guest_dataset['name'][i]}
    )
    for i in range(len(guest_dataset))
]
```

</hfoption>
<hfoption id="langgraph">

Hugging Face `datasets` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³ , `langchain.docstore.document` ëª¨ë“ˆì˜ `Document` ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```python
import datasets
from langchain.docstore.document import Document

# ë°ì´í„°ì…‹ ë¡œë“œ
guest_dataset = datasets.load_dataset("agents-course/unit3-invitees", split="train")

# ê° ì†ë‹˜ í•­ëª©ì„ Document ê°ì²´ë¡œ ë³€í™˜
docs = [
    Document(
        page_content="\n".join([
            f"Name: {guest['name']}",
            f"Relation: {guest['relation']}",
            f"Description: {guest['description']}",
            f"Email: {guest['email']}"
        ]),
        metadata={"name": guest["name"]}
    )
    for guest in guest_dataset
]
```

</hfoption>
</hfoptions>

ìœ„ ì½”ë“œì—ì„œëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
- ë°ì´í„°ì…‹ ë¡œë“œ
- ê° ì†ë‹˜ í•­ëª©ì„ í¬ë§·íŒ…ëœ ë‚´ìš©ì˜ `Document` ê°ì²´ë¡œ ë³€í™˜
- `Document` ê°ì²´ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥

ì´ì œ ëª¨ë“  ë°ì´í„°ê°€ ì˜ ì¤€ë¹„ë˜ì—ˆìœ¼ë‹ˆ, ê²€ìƒ‰ ì„¤ì •ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 2ë‹¨ê³„: ê²€ìƒ‰(Retriever) ë„êµ¬ ìƒì„±

ì´ì œ Alfredê°€ ì†ë‹˜ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ë§ì¶¤í˜• ë„êµ¬ë¥¼ ë§Œë“¤ì–´ë´…ì‹œë‹¤.

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

`langchain_community.retrievers` ëª¨ë“ˆì˜ `BM25Retriever`ë¥¼ ì‚¬ìš©í•´ ê²€ìƒ‰ ë„êµ¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.

<Tip>
  <code>BM25Retriever</code>ëŠ” ê²€ìƒ‰ì˜ ì¶œë°œì ìœ¼ë¡œ í›Œë¥­í•˜ì§€ë§Œ, ë” ê³ ê¸‰ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì´ í•„ìš”í•˜ë‹¤ë©´ <a href="https://www.sbert.net/">sentence-transformers</a>ì˜ ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ê¸°ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.
</Tip>

```python
from smolagents import Tool
from langchain_community.retrievers import BM25Retriever

class GuestInfoRetrieverTool(Tool):
    name = "guest_info_retriever"
    description = "ì†ë‹˜ì˜ ì´ë¦„ì´ë‚˜ ê´€ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°ˆë¼ ì†ë‹˜ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    inputs = {
        "query": {
            "type": "string",
            "description": "ì •ë³´ë¥¼ ì•Œê³  ì‹¶ì€ ì†ë‹˜ì˜ ì´ë¦„ ë˜ëŠ” ê´€ê³„."
        }
    }
    output_type = "string"

    def __init__(self, docs):
        self.is_initialized = False
        self.retriever = BM25Retriever.from_documents(docs)

    def forward(self, query: str):
        results = self.retriever.get_relevant_documents(query)
        if results:
            return "\n\n".join([doc.page_content for doc in results[:3]])
        else:
            return "ì¼ì¹˜í•˜ëŠ” ì†ë‹˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ë„êµ¬ ì´ˆê¸°í™”
guest_info_tool = GuestInfoRetrieverTool(docs)
```

ì´ ë„êµ¬ì˜ ë™ì‘ì„ ë‹¨ê³„ë³„ë¡œ ì‚´í´ë´…ì‹œë‹¤:
- `name`ê³¼ `description`ì€ ì—ì´ì „íŠ¸ê°€ ì–¸ì œ, ì–´ë–»ê²Œ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤
- `inputs`ëŠ” ë„êµ¬ê°€ ê¸°ëŒ€í•˜ëŠ” íŒŒë¼ë¯¸í„°(ì—¬ê¸°ì„œëŠ” ê²€ìƒ‰ ì¿¼ë¦¬)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤
- `BM25Retriever`ëŠ” ì„ë² ë”©ì´ í•„ìš” ì—†ëŠ” ê°•ë ¥í•œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤
- `forward` ë©”ì„œë“œëŠ” ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•´ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì†ë‹˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤

</hfoption>
<hfoption id="llama-index">

`llama_index.retrievers.bm25` ëª¨ë“ˆì˜ `BM25Retriever`ë¥¼ ì‚¬ìš©í•´ ê²€ìƒ‰ ë„êµ¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.

<Tip>
  <code>BM25Retriever</code>ëŠ” ê²€ìƒ‰ì˜ ì¶œë°œì ìœ¼ë¡œ í›Œë¥­í•˜ì§€ë§Œ, ë” ê³ ê¸‰ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì´ í•„ìš”í•˜ë‹¤ë©´ <a href="https://www.sbert.net/">sentence-transformers</a>ì˜ ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ê¸°ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.
</Tip>

```python
from llama_index.core.tools import FunctionTool
from llama_index.retrievers.bm25 import BM25Retriever

bm25_retriever = BM25Retriever.from_defaults(nodes=docs)

def get_guest_info_retriever(query: str) -> str:
    """ì†ë‹˜ì˜ ì´ë¦„ì´ë‚˜ ê´€ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°ˆë¼ ì†ë‹˜ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    results = bm25_retriever.retrieve(query)
    if results:
        return "\n\n".join([doc.text for doc in results[:3]])
    else:
        return "ì¼ì¹˜í•˜ëŠ” ì†ë‹˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ë„êµ¬ ì´ˆê¸°í™”
guest_info_tool = FunctionTool.from_defaults(get_guest_info_retriever)
```

ì´ ë„êµ¬ì˜ ë™ì‘ì„ ë‹¨ê³„ë³„ë¡œ ì‚´í´ë´…ì‹œë‹¤.
- docstringì€ ì—ì´ì „íŠ¸ê°€ ì–¸ì œ, ì–´ë–»ê²Œ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤
- íƒ€ì… ë°ì½”ë ˆì´í„°ëŠ” ë„êµ¬ê°€ ê¸°ëŒ€í•˜ëŠ” íŒŒë¼ë¯¸í„°(ì—¬ê¸°ì„œëŠ” ê²€ìƒ‰ ì¿¼ë¦¬)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤
- `BM25Retriever`ëŠ” ì„ë² ë”©ì´ í•„ìš” ì—†ëŠ” ê°•ë ¥í•œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤
- ë©”ì„œë“œëŠ” ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•´ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì†ë‹˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤

</hfoption>
<hfoption id="langgraph">

`langchain_community.retrievers` ëª¨ë“ˆì˜ `BM25Retriever`ë¥¼ ì‚¬ìš©í•´ ê²€ìƒ‰ ë„êµ¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.

<Tip>
  <code>BM25Retriever</code>ëŠ” ê²€ìƒ‰ì˜ ì¶œë°œì ìœ¼ë¡œ í›Œë¥­í•˜ì§€ë§Œ, ë” ê³ ê¸‰ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì´ í•„ìš”í•˜ë‹¤ë©´ <a href="https://www.sbert.net/">sentence-transformers</a>ì˜ ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ê¸°ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.
</Tip>

```python
from langchain_community.retrievers import BM25Retriever
from langchain.tools import Tool

bm25_retriever = BM25Retriever.from_documents(docs)

def extract_text(query: str) -> str:
    """ì†ë‹˜ì˜ ì´ë¦„ì´ë‚˜ ê´€ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°ˆë¼ ì†ë‹˜ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    results = bm25_retriever.invoke(query)
    if results:
        return "\n\n".join([doc.page_content for doc in results[:3]])
    else:
        return "ì¼ì¹˜í•˜ëŠ” ì†ë‹˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

guest_info_tool = Tool(
    name="guest_info_retriever",
    func=extract_text,
    description="ì†ë‹˜ì˜ ì´ë¦„ì´ë‚˜ ê´€ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°ˆë¼ ì†ë‹˜ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
)
```

ì´ ë„êµ¬ì˜ ë™ì‘ì„ ë‹¨ê³„ë³„ë¡œ ì‚´í´ë´…ì‹œë‹¤.
- `name`ê³¼ `description`ì€ ì—ì´ì „íŠ¸ê°€ ì–¸ì œ, ì–´ë–»ê²Œ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ ì´í•´í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤
- íƒ€ì… ë°ì½”ë ˆì´í„°ëŠ” ë„êµ¬ê°€ ê¸°ëŒ€í•˜ëŠ” íŒŒë¼ë¯¸í„°(ì—¬ê¸°ì„œëŠ” ê²€ìƒ‰ ì¿¼ë¦¬)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤
- `BM25Retriever`ëŠ” ì„ë² ë”©ì´ í•„ìš” ì—†ëŠ” ê°•ë ¥í•œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤
- ë©”ì„œë“œëŠ” ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•´ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì†ë‹˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤

</hfoption>
</hfoptions>

### 3ë‹¨ê³„: ë„êµ¬ë¥¼ Alfredì™€ í†µí•©í•˜ê¸°

ë§ˆì§€ë§‰ìœ¼ë¡œ, ëª¨ë“  ê²ƒì„ í†µí•©í•´ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ê³  ë§ì¶¤í˜• ë„êµ¬ë¥¼ ì¥ì°©í•´ë´…ì‹œë‹¤:

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
from smolagents import CodeAgent, InferenceClientModel

# Hugging Face ëª¨ë¸ ì´ˆê¸°í™”
model = InferenceClientModel()

# ì†ë‹˜ ì •ë³´ ë„êµ¬ë¥¼ í¬í•¨í•œ ê°ˆë¼ ì—ì´ì „íŠ¸ Alfred ìƒì„±
alfred = CodeAgent(tools=[guest_info_tool], model=model)

# ê°ˆë¼ ì¤‘ Alfredê°€ ë°›ì„ ìˆ˜ ìˆëŠ” ì˜ˆì‹œ ì¿¼ë¦¬
response = alfred.run("'Lady Ada Lovelace'ë¼ëŠ” ì†ë‹˜ì— ëŒ€í•´ ì•Œë ¤ì¤˜.")

print("ğŸ© Alfredì˜ ë‹µë³€:")
print(response)
```

ì˜ˆìƒ ì¶œë ¥:

```
ğŸ© Alfredì˜ ë‹µë³€:
ìˆ˜ì§‘í•œ ì •ë³´ì— ë”°ë¥´ë©´, Lady Ada LovelaceëŠ” ì €ëª…í•œ ìˆ˜í•™ìì´ì ì¹œêµ¬ì…ë‹ˆë‹¤. ê·¸ë…€ëŠ” ìˆ˜í•™ê³¼ ì»´í“¨íŒ… ë¶„ì•¼ì˜ ì„ êµ¬ì ì¸ ì—…ì ìœ¼ë¡œ ìœ ëª…í•˜ë©°, Charles Babbageì˜ í•´ì„ê¸°ê´€ì— ëŒ€í•œ ì‘ì—…ìœ¼ë¡œ ì¸í•´ ì¢…ì¢… ìµœì´ˆì˜ ì»´í“¨í„° í”„ë¡œê·¸ë˜ë¨¸ë¡œ ë¶ˆë¦½ë‹ˆë‹¤. ì´ë©”ì¼ ì£¼ì†ŒëŠ” ada.lovelace@example.comì…ë‹ˆë‹¤.
```

ìµœì¢… ë‹¨ê³„ì—ì„œ ì¼ì–´ë‚˜ëŠ” ì¼:
- `InferenceClientModel` í´ë˜ìŠ¤ë¡œ Hugging Face ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤
- `CodeAgent`ë¡œ ì—ì´ì „íŠ¸(Alfred)ë¥¼ ìƒì„±í•˜ê³ , ìš°ë¦¬ê°€ ë§Œë“  ë„êµ¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤
- Alfredì—ê²Œ "Lady Ada Lovelace"ë¼ëŠ” ì†ë‹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤

</hfoption>
<hfoption id="llama-index">

```python
from llama_index.core.agent.workflow import AgentWorkflow
from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI

# Hugging Face ëª¨ë¸ ì´ˆê¸°í™”
llm = HuggingFaceInferenceAPI(model_name="Qwen/Qwen2.5-Coder-32B-Instruct")

# ì†ë‹˜ ì •ë³´ ë„êµ¬ë¥¼ í¬í•¨í•œ ê°ˆë¼ ì—ì´ì „íŠ¸ Alfred ìƒì„±
alfred = AgentWorkflow.from_tools_or_functions(
    [guest_info_tool],
    llm=llm,
)

# ê°ˆë¼ ì¤‘ Alfredê°€ ë°›ì„ ìˆ˜ ìˆëŠ” ì˜ˆì‹œ ì¿¼ë¦¬
response = await alfred.run("'Lady Ada Lovelace'ë¼ëŠ” ì†ë‹˜ì— ëŒ€í•´ ì•Œë ¤ì¤˜.")

print("ğŸ© Alfredì˜ ë‹µë³€:")
print(response)
```

ì˜ˆìƒ ì¶œë ¥:

```
ğŸ© Alfredì˜ ë‹µë³€:
Lady Ada LovelaceëŠ” ì €ëª…í•œ ìˆ˜í•™ìì´ì ì¹œêµ¬ë¡œ, ìˆ˜í•™ê³¼ ì»´í“¨íŒ… ë¶„ì•¼ì˜ ì„ êµ¬ì ì¸ ì—…ì ìœ¼ë¡œ ìœ ëª…í•©ë‹ˆë‹¤. ê·¸ë…€ëŠ” Charles Babbageì˜ í•´ì„ê¸°ê´€ì— ëŒ€í•œ ì‘ì—…ìœ¼ë¡œ ì¸í•´ ìµœì´ˆì˜ ì»´í“¨í„° í”„ë¡œê·¸ë˜ë¨¸ë¡œ í‰ê°€ë°›ìŠµë‹ˆë‹¤. ì´ë©”ì¼ì€ ada.lovelace@example.comì…ë‹ˆë‹¤.
```

ìµœì¢… ë‹¨ê³„ì—ì„œ ì¼ì–´ë‚˜ëŠ” ì¼:
- `HuggingFaceInferenceAPI` í´ë˜ìŠ¤ë¡œ Hugging Face ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤
- ìš°ë¦¬ê°€ ë§Œë“  ë„êµ¬ë¥¼ í¬í•¨í•´ `AgentWorkflow`ë¡œ ì—ì´ì „íŠ¸(Alfred)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
- Alfredì—ê²Œ "Lady Ada Lovelace"ë¼ëŠ” ì†ë‹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤

</hfoption>
<hfoption id="langgraph">

```python
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages
from langchain_core.messages import AnyMessage, HumanMessage, AIMessage
from langgraph.prebuilt import ToolNode
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition
from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë° ë„êµ¬ í¬í•¨
llm = HuggingFaceEndpoint(
    repo_id="Qwen/Qwen2.5-Coder-32B-Instruct",
    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,
)

chat = ChatHuggingFace(llm=llm, verbose=True)
tools = [guest_info_tool]
chat_with_tools = chat.bind_tools(tools)

# AgentState ë° ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ìƒì„±
class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], add_messages]

def assistant(state: AgentState):
    return {
        "messages": [chat_with_tools.invoke(state["messages"])],
    }

## ê·¸ë˜í”„ ìƒì„±
builder = StateGraph(AgentState)

# ë…¸ë“œ ì •ì˜: ì‹¤ì œ ì‘ì—… ìˆ˜í–‰
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# ì—£ì§€ ì •ì˜: ì œì–´ íë¦„ ê²°ì •

</code_block_to_apply_changes_from>
</hfoptions> 