# 소개

![Bonus Unit 1 Thumbnail](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit1/thumbnail.jpg)

첫 번째 **보너스 유닛**에 오신 것을 환영합니다! 여기서는 **함수 호출(Function Calling)을 위한 대형 언어 모델(LLM) 파인튜닝**을 배웁니다.

LLM 분야에서 함수 호출은 빠르게 *필수 기술*이 되고 있습니다.

Unit 1에서처럼 프롬프트 기반 접근만 사용하는 대신, 함수 호출은 모델이 **훈련 단계에서 직접 행동을 취하고 관찰을 해석**하도록 학습시켜 AI를 더 견고하게 만듭니다.

> **이 보너스 유닛은 언제 하면 좋을까요?**
>
> 이 섹션은 **선택 사항**이며 Unit 1보다 더 고급 내용입니다. 지금 바로 진행해도 되고, 이 과정을 통해 지식이 쌓인 후 다시 돌아와도 괜찮습니다.
>
> 걱정하지 마세요. 이 보너스 유닛은 함수 호출을 위한 파인튜닝의 핵심 개념을 모두 안내하므로, 파인튜닝의 내부 동작을 아직 모른다 해도 따라올 수 있습니다.

이 보너스 유닛을 잘 따라가기 위한 권장 사전 지식:

1. Transformers로 LLM을 파인튜닝하는 방법을 알면 좋습니다. 모른다면 [여기](https://huggingface.co/learn/nlp-course/chapter3/1?fw=pt)를 참고하세요.

2. `SFTTrainer`를 사용해 모델을 파인튜닝하는 방법을 알면 좋습니다. 자세한 내용은 [이 문서](https://huggingface.co/learn/nlp-course/en/chapter11/1)를 참고하세요.

---

## 학습 목표

1. **함수 호출(Function Calling)**  
   최신 LLM이 대화를 구조화하여 **툴(도구)**을 트리거하는 방법

2. **LoRA (Low-Rank Adaptation)**  
   계산 및 저장 비용을 줄여주는 **경량·효율적** 파인튜닝 기법. LoRA는 대형 모델 학습을 *더 빠르고 저렴하며 쉽게* 만듭니다.

3. **생각 → 행동 → 관찰(Thought → Act → Observe) 사이클**  
   모델이 언제(그리고 어떻게) 함수를 호출할지 결정하고, 중간 단계를 추적하며, 외부 도구나 API의 결과를 해석하는 구조화된 접근법

4. **새로운 특수 토큰**  
   모델이 다음을 구분할 수 있도록 돕는 **특수 마커** 도입:
   - 내부 "chain-of-thought" 추론
   - 외부 함수 호출
   - 외부 도구에서 돌아오는 응답

---

이 보너스 유닛을 마치면 다음을 할 수 있습니다:

- **툴 관련 API의 내부 동작**을 이해
- **LoRA 기법으로 모델 파인튜닝**
- **생각→행동→관찰 사이클 구현 및 수정**으로 견고하고 유지보수 쉬운 함수 호출 워크플로우 제작
- **특수 토큰 설계 및 활용**으로 모델의 내부 추론과 외부 행동을 명확히 분리

그리고 **직접 함수 호출이 가능한 모델을 파인튜닝**하게 됩니다! 🔥

이제 **함수 호출(Function Calling)**의 세계로 들어가 봅시다! 