# LlamaIndex에서 에이전트 워크플로우 만들기

LlamaIndex의 워크플로우는 코드를 순차적이고 관리하기 쉬운 단계로 구성할 수 있는 구조화된 방법을 제공합니다.

이러한 워크플로우는 `이벤트(Events)`에 의해 트리거되는 `단계(Steps)`를 정의하고, 이 단계들은 다시 다음 단계를 트리거하는 `이벤트`를 발생시킵니다.
Alfred가 보여주는 RAG 작업을 위한 LlamaIndex 워크플로우를 살펴보겠습니다.

![워크플로우 도식](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit2/llama-index/workflows.png)

**워크플로우는 다음과 같은 주요 이점을 제공합니다:**

- 코드를 개별 단계로 명확하게 구성
- 유연한 제어 흐름을 위한 이벤트 기반 아키텍처
- 단계 간 타입 안전 통신
- 내장된 상태 관리
- 단순하고 복잡한 에이전트 상호작용 모두 지원

짐작하셨겠지만, **워크플로우는 에이전트의 자율성과 전체 워크플로우에 대한 제어를 유지하는 사이에서 훌륭한 균형을 이룹니다.**

그럼 이제 직접 워크플로우를 만드는 방법을 배워보겠습니다!

## 워크플로우 만들기

<Tip>
<a href="https://huggingface.co/agents-course/notebooks/blob/main/unit2/llama-index/workflows.ipynb" target="_blank">이 노트북</a>에서 Google Colab을 사용하여 실행할 수 있는 코드를 따라할 수 있습니다.
</Tip>

### 기본 워크플로우 생성

<details>
<summary>워크플로우 패키지 설치하기</summary>
<a href="./llama-hub">LlamaHub 섹션</a>에서 소개한 것처럼, 다음 명령어로 워크플로우 패키지를 설치할 수 있습니다:

```python
pip install llama-index-utils-workflow
```
</details>

`Workflow`를 상속받는 클래스를 정의하고 함수에 `@step` 데코레이터를 사용하여 단일 단계 워크플로우를 만들 수 있습니다.
또한 워크플로우의 시작과 끝을 나타내는 특별한 이벤트인 `StartEvent`와 `StopEvent`도 추가해야 합니다.

```python
from llama_index.core.workflow import StartEvent, StopEvent, Workflow, step

class MyWorkflow(Workflow):
    @step
    async def my_step(self, ev: StartEvent) -> StopEvent:
        # 여기서 작업 수행
        return StopEvent(result="Hello, world!")


w = MyWorkflow(timeout=10, verbose=False)
result = await w.run()
```

보시다시피 `w.run()`을 호출하여 워크플로우를 실행할 수 있습니다.

### 여러 단계 연결하기

여러 단계를 연결하려면 **단계 사이에 데이터를 전달하는 사용자 정의 이벤트를 생성**해야 합니다.
이를 위해 첫 번째 단계의 출력을 두 번째 단계로 전달하는 `Event`를 추가해야 합니다.

```python
from llama_index.core.workflow import Event

class ProcessingEvent(Event):
    intermediate_result: str

class MultiStepWorkflow(Workflow):
    @step
    async def step_one(self, ev: StartEvent) -> ProcessingEvent:
        # 초기 데이터 처리
        return ProcessingEvent(intermediate_result="1단계 완료")

    @step
    async def step_two(self, ev: ProcessingEvent) -> StopEvent:
        # 중간 결과 사용
        final_result = f"처리 완료: {ev.intermediate_result}"
        return StopEvent(result=final_result)

w = MultiStepWorkflow(timeout=10, verbose=False)
result = await w.run()
result
```

여기서 타입 힌팅은 워크플로우가 올바르게 실행되도록 보장하기 때문에 중요합니다. 이제 조금 더 복잡하게 만들어보겠습니다!

### 루프와 분기

타입 힌팅은 워크플로우의 가장 강력한 부분입니다. 이를 통해 더 복잡한 워크플로우를 위한 분기, 루프, 조인을 만들 수 있기 때문입니다.

유니온 연산자 `|`를 사용하여 **루프를 만드는** 예제를 살펴보겠습니다.
아래 예제에서는 `LoopEvent`가 단계의 입력으로 사용되고 출력으로도 반환될 수 있음을 볼 수 있습니다.

```python
from llama_index.core.workflow import Event
import random


class ProcessingEvent(Event):
    intermediate_result: str


class LoopEvent(Event):
    loop_output: str


class MultiStepWorkflow(Workflow):
    @step
    async def step_one(self, ev: StartEvent | LoopEvent) -> ProcessingEvent | LoopEvent:
        if random.randint(0, 1) == 0:
            print("나쁜 일이 발생했습니다")
            return LoopEvent(loop_output="1단계로 돌아갑니다.")
        else:
            print("좋은 일이 발생했습니다")
            return ProcessingEvent(intermediate_result="첫 번째 단계 완료.")

    @step
    async def step_two(self, ev: ProcessingEvent) -> StopEvent:
        # 중간 결과 사용
        final_result = f"처리 완료: {ev.intermediate_result}"
        return StopEvent(result=final_result)


w = MultiStepWorkflow(verbose=False)
result = await w.run()
result
```

### 워크플로우 그리기

워크플로우를 시각화할 수도 있습니다. `draw_all_possible_flows` 함수를 사용하여 워크플로우를 그려보겠습니다. 이는 워크플로우를 HTML 파일로 저장합니다.

```python
from llama_index.utils.workflow import draw_all_possible_flows

w = ... # 이전 섹션에서 정의한 대로
draw_all_possible_flows(w, "flow.html")
```

![워크플로우 그리기](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit2/llama-index/workflow-draw.png)

이 과정에서 다룰 마지막 멋진 기능이 하나 더 있는데, 바로 워크플로우에 상태를 추가하는 기능입니다.

### 상태 관리

상태 관리는 워크플로우의 상태를 추적하여 모든 단계가 동일한 상태에 접근할 수 있도록 하고 싶을 때 유용합니다.
이는 단계 함수의 매개변수 위에 `Context` 타입 힌트를 사용하여 구현할 수 있습니다.

```python
from llama_index.core.workflow import Context, StartEvent, StopEvent


@step
async def query(self, ctx: Context, ev: StartEvent) -> StopEvent:
    # 컨텍스트에 쿼리 저장
    await ctx.set("query", "프랑스의 수도는 무엇인가요?")

    # 컨텍스트와 이벤트로 작업 수행
    val = ...

    # 컨텍스트에서 쿼리 검색
    query = await ctx.get("query")

    return StopEvent(result=val)
```

좋습니다! 이제 LlamaIndex에서 기본 워크플로우를 만드는 방법을 알게 되었습니다!

<Tip>워크플로우에 대한 더 복잡한 내용은 <a href="https://docs.llamaindex.ai/en/stable/understanding/workflows/">LlamaIndex 문서</a>에서 배울 수 있습니다.</Tip>

하지만 워크플로우를 만드는 또 다른 방법이 있는데, 바로 `AgentWorkflow` 클래스를 사용하는 것입니다. 이를 사용하여 다중 에이전트 워크플로우를 만드는 방법을 살펴보겠습니다.

## 다중 에이전트 워크플로우로 워크플로우 자동화하기

수동으로 워크플로우를 만드는 대신, **`AgentWorkflow` 클래스를 사용하여 다중 에이전트 워크플로우를 만들 수** 있습니다.
`AgentWorkflow`는 워크플로우 에이전트를 사용하여 전문화된 능력을 바탕으로 서로 작업을 넘겨줄 수 있는 하나 이상의 에이전트 시스템을 만들 수 있게 해줍니다.
이를 통해 서로 다른 에이전트가 작업의 다른 측면을 처리하는 복잡한 에이전트 시스템을 구축할 수 있습니다.
`llama_index.core.agent`에서 클래스를 가져오는 대신, `llama_index.core.agent.workflow`에서 에이전트 클래스를 가져올 것입니다.
`AgentWorkflow` 생성자에서 하나의 에이전트를 루트 에이전트로 지정해야 합니다.
사용자 메시지가 들어오면 먼저 루트 에이전트로 라우팅됩니다.

각 에이전트는 다음과 같은 작업을 수행할 수 있습니다:

- 자신의 도구를 사용하여 직접 요청 처리
- 작업에 더 적합한 다른 에이전트에게 작업 전달
- 사용자에게 응답 반환

다중 에이전트 워크플로우를 만드는 방법을 살펴보겠습니다.

```python
from llama_index.core.agent.workflow import AgentWorkflow, ReActAgent
from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI

# 몇 가지 도구 정의
def add(a: int, b: int) -> int:
    """두 숫자를 더합니다."""
    return a + b

def multiply(a: int, b: int) -> int:
    """두 숫자를 곱합니다."""
    return a * b

llm = HuggingFaceInferenceAPI(model_name="Qwen/Qwen2.5-Coder-32B-Instruct")

# 함수를 FunctionTool 없이 직접 전달할 수 있습니다 -- 함수와 독스트링이 이름/설명으로 파싱됩니다
multiply_agent = ReActAgent(
    name="multiply_agent",
    description="두 정수를 곱할 수 있습니다",
    system_prompt="숫자를 곱하는 도구를 사용할 수 있는 도움이 되는 어시스턴트입니다.",
    tools=[multiply],
    llm=llm,
)

addition_agent = ReActAgent(
    name="add_agent",
    description="두 정수를 더할 수 있습니다",
    system_prompt="숫자를 더하는 도구를 사용할 수 있는 도움이 되는 어시스턴트입니다.",
    tools=[add],
    llm=llm,
)

# 워크플로우 생성
workflow = AgentWorkflow(
    agents=[multiply_agent, addition_agent],
    root_agent="multiply_agent",
)

# 시스템 실행
response = await workflow.run(user_msg="5와 3을 더할 수 있나요?")
```

에이전트 도구는 앞서 언급한 워크플로우 상태도 수정할 수 있습니다. 워크플로우를 시작하기 전에 모든 에이전트가 사용할 수 있는 초기 상태 딕셔너리를 제공할 수 있습니다.
상태는 워크플로우 컨텍스트의 state 키에 저장됩니다. 이는 각각의 새로운 사용자 메시지를 보강하는 state_prompt에 주입됩니다.

이전 예제를 수정하여 함수 호출을 카운트하는 카운터를 주입해보겠습니다:

```python
from llama_index.core.workflow import Context

# 도구 정의
async def add(ctx: Context, a: int, b: int) -> int:
    """두 숫자를 더합니다."""
    # 카운트 업데이트
    cur_state = await ctx.get("state")
    cur_state["num_fn_calls"] += 1
    await ctx.set("state", cur_state)

    return a + b

async def multiply(ctx: Context, a: int, b: int) -> int:
    """두 숫자를 곱합니다."""
    # 카운트 업데이트
    cur_state = await ctx.get("state")
    cur_state["num_fn_calls"] += 1
    await ctx.set("state", cur_state)

    return a * b

...

workflow = AgentWorkflow(
    agents=[multiply_agent, addition_agent],
    root_agent="multiply_agent",
    initial_state={"num_fn_calls": 0},
    state_prompt="현재 상태: {state}. 사용자 메시지: {msg}",
)

# 컨텍스트와 함께 워크플로우 실행
ctx = Context(workflow)
response = await workflow.run(user_msg="5와 3을 더할 수 있나요?", ctx=ctx)

# 상태를 가져와서 검사
state = await ctx.get("state")
print(state["num_fn_calls"])
```

축하합니다! 이제 LlamaIndex의 에이전트 기초를 마스터했습니다! 🎉

마지막으로 퀴즈를 풀면서 지식을 공고히 해봅시다! 🚀 