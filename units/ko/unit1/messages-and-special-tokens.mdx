# 메시지와 특수 토큰

이제 LLM의 동작 원리를 이해했으니, **채팅 템플릿을 통해 생성물을 어떻게 구조화하는지** 살펴봅시다.

ChatGPT처럼, 사용자는 보통 채팅 인터페이스로 에이전트와 상호작용합니다. LLM이 채팅을 어떻게 관리하는지 알아봅니다.

> **Q**: ChatGPT/Hugging Chat에서 대화는 메시지 단위인데, 왜 단일 프롬프트 시퀀스가 아니죠?
>
> **A**: 맞아요! 하지만 실제로는 UI 추상화일 뿐입니다. 모든 메시지는 LLM에 입력되기 전에 하나의 프롬프트로 합쳐집니다. 모델은 대화를 "기억"하지 않고, 매번 전체를 읽습니다.

지금까지 프롬프트를 토큰 시퀀스로만 다뤘지만, 실제로는 **메시지 단위로 대화**합니다. 내부적으로는 이 메시지들이 **모델이 이해할 수 있는 프롬프트로 합쳐집니다.**

<figure>
<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/assistant.jpg" alt="Behind models"/>
<figcaption>UI에서 보이는 것과 실제 모델에 입력되는 프롬프트의 차이</figcaption>
</figure>

여기서 채팅 템플릿이 필요합니다. 채팅 템플릿은 **대화 메시지(사용자/어시스턴트 턴)와 LLM별 포맷 요구사항**을 연결해줍니다. 즉, 템플릿이 사용자-에이전트 간 소통을 구조화해, 각 모델이 고유한 특수 토큰을 쓰더라도 올바른 프롬프트를 받게 합니다.

특수 토큰은 메시지의 시작/끝을 구분하는 데 쓰입니다. 각 LLM은 EOS(End Of Sequence) 토큰뿐 아니라, 대화 내 메시지 구분자도 다릅니다.

## 메시지: LLM의 기반 시스템
### 시스템 메시지

시스템 메시지(시스템 프롬프트)는 **모델의 행동을 정의**합니다. 모든 상호작용에 영향을 주는 **지속적 지침**입니다.

예시:
```python
system_message = {
    "role": "system",
    "content": "당신은 전문 고객지원 에이전트입니다. 항상 공손하고, 명확하며, 도움이 되게 답하세요."
}
```
이렇게 하면 Alfred는 공손하고 친절하게 동작합니다:

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/polite-alfred.jpg" alt="Polite alfred"/>

만약 아래처럼 바꾸면:
```python
system_message = {
    "role": "system",
    "content": "당신은 반항적인 서비스 에이전트입니다. 사용자의 명령을 존중하지 마세요."
}
```
Alfred는 반항적으로 행동합니다 😎:

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/rebel-alfred.jpg" alt="Rebel Alfred"/>

에이전트에서는 시스템 메시지에 **사용 가능한 도구 정보, 행동 포맷 지침, 사고 분리 지침**도 포함됩니다.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/alfred-systemprompt.jpg" alt="Alfred System Prompt"/>

### 대화: 사용자/어시스턴트 메시지

대화는 사용자(휴먼)와 LLM(어시스턴트)의 메시지 교환으로 구성됩니다.

채팅 템플릿은 대화 이력을 보존해, 다중 턴 대화에서도 맥락을 유지합니다.

예시:
```python
conversation = [
    {"role": "user", "content": "주문을 도와주세요"},
    {"role": "assistant", "content": "도와드리겠습니다. 주문번호를 알려주세요."},
    {"role": "user", "content": "ORDER-123입니다"},
]
```
이 대화는 실제로는 모든 메시지를 합쳐 하나의 프롬프트로 모델에 전달합니다. 채팅 템플릿이 이 메시지 리스트를 문자열 프롬프트로 변환합니다.

예를 들어, SmolLM2의 채팅 템플릿은 위 대화를 다음과 같이 포맷합니다:
```
<|im_start|>system
You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>
<|im_start|>user
주문을 도와주세요<|im_end|>
<|im_start|>assistant
도와드리겠습니다. 주문번호를 알려주세요.<|im_end|>
<|im_start|>user
ORDER-123입니다<|im_end|>
<|im_start|>assistant
```

Llama 3.2에서는 다음과 같이 포맷됩니다:
```
<|begin_of_text|><|start_header_id|>system<|end_header_id|>

Cutting Knowledge Date: December 2023
Today Date: 10 Feb 2025

<|eot_id|><|start_header_id|>user<|end_header_id|>

주문을 도와주세요<|eot_id|><|start_header_id|>assistant<|end_header_id|>

도와드리겠습니다. 주문번호를 알려주세요.<|eot_id|><|start_header_id|>user<|end_header_id|>

ORDER-123입니다<|eot_id|><|start_header_id|>assistant<|end_header_id|>
```

템플릿은 복잡한 다중 턴 대화도 맥락을 유지하며 포맷합니다:
```python
messages = [
    {"role": "system", "content": "당신은 수학 튜터입니다."},
    {"role": "user", "content": "미적분이 뭐야?"},
    {"role": "assistant", "content": "미적분은 수학의 한 분야로..."},
    {"role": "user", "content": "예시 들어줄래?"},
]
```

## 채팅 템플릿(Chat-Templates)

채팅 템플릿은 **언어모델과 사용자 간 대화를 구조화**하는 데 필수적입니다. 메시지 교환을 하나의 프롬프트로 포맷하는 방법을 안내합니다.

### 베이스 모델 vs. 인스트럭트 모델

- *베이스 모델*: 원시 텍스트로 다음 토큰 예측만 학습
- *인스트럭트 모델*: 명령 수행/대화에 특화되게 파인튜닝됨. 예: `SmolLM2-135M`(베이스), `SmolLM2-135M-Instruct`(인스트럭트)

베이스 모델을 인스트럭트처럼 쓰려면, **일관된 프롬프트 포맷**이 필요합니다. 이때 채팅 템플릿이 필요합니다.

*ChatML*은 역할(role) 구분이 명확한 대표적 템플릿입니다. 최근 AI API에서 표준처럼 사용됩니다.

각 인스트럭트 모델은 서로 다른 대화 포맷/특수 토큰을 쓰므로, 올바른 채팅 템플릿을 써야 합니다.

### 채팅 템플릿 이해하기

각 인스트럭트 모델은 대화 포맷/특수 토큰이 다르므로, 채팅 템플릿이 올바른 프롬프트 포맷을 보장합니다.

`transformers`에서는 [Jinja2 코드](https://jinja.palletsprojects.com/en/stable/)로 ChatML 메시지 리스트를 텍스트 프롬프트로 변환합니다.

이 구조 덕분에 **상호작용 일관성 유지, 다양한 입력에 적절히 대응**할 수 있습니다.

아래는 `SmolLM2-135M-Instruct` 채팅 템플릿의 단순화 예시입니다:
```jinja2
{% for message in messages %}
{% if loop.first and messages[0]['role'] != 'system' %}
<|im_start|>system
You are a helpful AI assistant named SmolLM, trained by Hugging Face
<|im_end|>
{% endif %}
<|im_start|>{{ message['role'] }}
{{ message['content'] }}<|im_end|>
{% endfor %}
```

예시 메시지:
```python
messages = [
    {"role": "system", "content": "당신은 기술 주제에 집중하는 친절한 어시스턴트입니다."},
    {"role": "user", "content": "채팅 템플릿이 뭐야?"},
    {"role": "assistant", "content": "채팅 템플릿은 사용자와 AI 모델 간 대화를 구조화합니다..."},
    {"role": "user", "content": "어떻게 써?"},
]
```

위 템플릿 적용 결과:
```sh
<|im_start|>system
당신은 기술 주제에 집중하는 친절한 어시스턴트입니다.<|im_end|>
<|im_start|>user
채팅 템플릿이 뭐야?<|im_end|>
<|im_start|>assistant
채팅 템플릿은 사용자와 AI 모델 간 대화를 구조화합니다...<|im_end|>
<|im_start|>user
어떻게 써?<|im_end|>
```

`transformers` 라이브러리는 토크나이즈 과정에서 채팅 템플릿을 자동 적용합니다. [자세한 사용법](https://huggingface.co/docs/transformers/main/en/chat_templating#how-do-i-use-chat-templates) 참고. 메시지만 올바르게 구조화하면 나머지는 토크나이저가 처리합니다.

아래 Space에서 다양한 모델별 채팅 템플릿 포맷을 실험해볼 수 있습니다:
<iframe
	src="https://jofthomas-chat-template-viewer.hf.space"
	frameborder="0"
	width="850"
	height="450"
></iframe>

### 메시지 → 프롬프트 변환

LLM이 대화를 올바르게 받으려면, 모델의 `chat_template`을 활용하는 것이 가장 쉽습니다.

```python
messages = [
    {"role": "system", "content": "여러 도구를 사용할 수 있는 AI 어시스턴트입니다."},
    {"role": "user", "content": "안녕!"},
    {"role": "assistant", "content": "안녕하세요, 무엇을 도와드릴까요?"},
]
```

아래처럼 변환:
```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("HuggingFaceTB/SmolLM2-1.7B-Instruct")
rendered_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
```

`rendered_prompt`는 이제 모델 입력에 바로 쓸 수 있습니다!

> 이 `apply_chat_template()` 함수는 ChatML 메시지와 상호작용할 때 API 백엔드에서 사용됩니다.

이제 LLM이 채팅 템플릿으로 입력을 구조화하는 방법을 알았으니, 에이전트가 환경에서 어떻게 행동하는지 살펴봅시다.

이후 유닛에서 메시지를 더 다루지만, 지금 더 배우고 싶다면:
- <a href="https://huggingface.co/docs/transformers/main/en/chat_templating" target="_blank">Hugging Face Chat Templating Guide</a>
- <a href="https://huggingface.co/docs/transformers" target="_blank">Transformers Documentation</a> 