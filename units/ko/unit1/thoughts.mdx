# 생각(Thought): 내부 추론과 ReAct 접근법

<Tip>
이 섹션에서는 AI 에이전트의 내부 동작, 즉 추론과 계획 능력을 다룹니다. 에이전트가 내부 대화를 통해 정보를 분석하고, 복잡한 문제를 단계별로 쪼개고, 다음 행동을 결정하는 과정을 살펴봅니다. 또한, 모델이 "단계별로 생각"하도록 유도하는 ReAct 프롬프트 기법도 소개합니다.
</Tip>

생각(Thought)은 **에이전트가 과제를 해결하기 위해 내부적으로 추론·계획하는 과정**입니다.

이는 에이전트의 LLM이 **프롬프트에 주어진 정보를 분석**하는 능력을 활용합니다.

즉, 에이전트의 내부 대화로, 당면한 과제를 어떻게 풀지 전략을 세우는 단계입니다.

에이전트의 생각은 현재 관찰(Observation)을 바탕으로 다음 행동을 결정합니다.

이 과정을 통해 에이전트는 **복잡한 문제를 더 작은 단계로 쪼개고, 과거 경험을 반영하며, 새로운 정보에 따라 계획을 계속 조정**할 수 있습니다.

생각의 예시:

| 생각 유형 | 예시 |
|-----------|------|
| 계획 | "이 작업을 1) 데이터 수집, 2) 트렌드 분석, 3) 보고서 생성 3단계로 나눠야겠다" |
| 분석 | "에러 메시지로 보아 DB 연결 파라미터에 문제가 있다" |
| 의사결정 | "예산 제약을 고려해 중간 옵션을 추천해야겠다" |
| 문제해결 | "코드 최적화 전, 병목 구간을 먼저 프로파일링해야겠다" |
| 메모리 통합 | "사용자가 파이썬을 선호한다고 했으니 예시도 파이썬으로 제공" |
| 자기반성 | "이전 접근법이 별로였으니 다른 전략을 써야겠다" |
| 목표설정 | "작업 완료를 위해 우선 수락 기준부터 정해야겠다" |
| 우선순위 | "보안 취약점 해결이 신규 기능 추가보다 우선" |

> **참고:** 함수 호출 특화 LLM에서는 생각 단계가 생략될 수 있습니다. (자세한 내용은 Actions 섹션 참고)

## ReAct 접근법

핵심 기법 중 하나가 **ReAct(Reasoning+Acting) 접근법**입니다.

ReAct는 "Let's think step by step"(단계별로 생각해보자)라는 프롬프트를 추가해, LLM이 최종 답이 아니라 **계획을 먼저 생성**하도록 유도합니다. 즉, 문제를 *하위 과제*로 쪼개게 만듭니다.

이렇게 하면 모델이 세부 단계를 더 꼼꼼히 고려해, 곧바로 답을 내는 것보다 오류가 줄어듭니다.

<figure>
<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/ReAct.png" alt="ReAct"/>
<figcaption>(d)는 "Let's think step by step" 프롬프트를 활용한 ReAct 예시입니다.</figcaption>
</figure>

<Tip>
최근에는 추론 전략에 대한 관심이 높아지고 있습니다. Deepseek R1, OpenAI o1 등은 "답변 전 생각"을 하도록 파인튜닝된 모델입니다. 이들은 `<think>...</think>` 특수 토큰으로 _생각_ 구간을 항상 포함하도록 학습되었습니다. 이는 단순 프롬프트 기법이 아니라, 수천 개 예시로 기대 동작을 학습시키는 훈련 방식입니다.
</Tip>

---
이제 생각(Thought) 과정을 이해했으니, 다음 단계인 행동(Act)으로 넘어갑니다. 