# 도구란 무엇인가?

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/whiteboard-check-2.jpg" alt="Unit 1 planning"/>

AI 에이전트의 핵심은 **행동(액션)을 취하는 능력**입니다. 이 행동은 **도구(Tool)**를 통해 이뤄집니다.

이 섹션에서는 도구란 무엇이며, 효과적으로 설계하는 방법, 시스템 메시지에 통합하는 방법을 배웁니다.

에이전트에 적절한 도구를 제공하고, 도구의 동작을 명확히 설명하면 AI의 능력을 크게 확장할 수 있습니다. 시작해봅시다!

## AI 도구란?

**도구는 LLM에 제공되는 함수**입니다. 이 함수는 **명확한 목적**을 가져야 합니다.

AI 에이전트에서 자주 쓰이는 도구 예시:

| 도구 | 설명 |
|------|------|
| 웹 검색 | 인터넷에서 최신 정보 검색 |
| 이미지 생성 | 텍스트 설명으로 이미지 생성 |
| 검색/조회 | 외부 소스에서 정보 검색 |
| API 인터페이스 | 외부 API(GitHub, YouTube 등)와 상호작용 |

이 외에도, 어떤 용도든 도구를 만들 수 있습니다!

좋은 도구는 **LLM의 한계를 보완**하는 역할을 합니다.

예를 들어, 산술 연산이 필요하다면 LLM에 **계산기 도구**를 제공하는 것이 모델 자체에 맡기는 것보다 훨씬 정확합니다.

또한, **LLM은 학습 시점 이후의 정보는 알지 못하므로**, 최신 데이터가 필요하다면 반드시 도구로 제공해야 합니다.

예: LLM에 오늘 날씨를 직접 물으면 임의로 답할 수 있지만, 검색 도구를 제공하면 실제 데이터를 가져올 수 있습니다.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/weather.jpg" alt="Weather"/>

- 도구에는 다음이 포함되어야 합니다:
  - **무엇을 하는지 설명하는 텍스트**
  - *실행 가능한 함수*
  - *타입이 명확한 인자*
  - (선택) 출력 타입

## 도구는 어떻게 동작하는가?

LLM은 텍스트 입출력만 가능하므로, 도구를 직접 호출할 수 없습니다. 도구를 제공한다는 것은 LLM에 도구의 존재를 알려주고, 필요할 때 도구 호출을 텍스트로 생성하도록 지시하는 것입니다.

예를 들어, "파리 날씨"를 묻는 질문에 LLM이 weather_tool('Paris')와 같은 도구 호출 텍스트를 생성하면, **에이전트가 이 응답을 읽고 실제 도구를 실행**해 결과를 얻습니다.

이 과정은 사용자에게는 보이지 않으며, 에이전트가 내부적으로 처리합니다. 사용자는 LLM이 직접 도구를 쓴 것처럼 느끼지만, 실제로는 에이전트가 실행한 것입니다.

이 과정은 이후 유닛에서 더 자세히 다룹니다.

## LLM에 도구를 제공하는 방법

정답은 시스템 프롬프트에 도구 설명을 텍스트로 추가하는 것입니다:

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/Agent_system_prompt.png" alt="System prompt for tools"/>

이때 중요한 것은:
1. **도구의 기능 설명**
2. **정확한 입력값 명시**

그래서 도구 설명은 보통 프로그래밍 언어나 JSON 등 명확한 구조로 작성합니다.

예시로, 두 정수를 곱하는 **계산기 도구**를 만들어봅시다:

```python
def calculator(a: int, b: int) -> int:
    """두 정수를 곱합니다."""
    return a * b
```

이 도구의 설명은 다음과 같습니다:
- 이름: calculator
- 설명: 두 정수를 곱함
- 입력: a(int), b(int)
- 출력: int

이 정보를 LLM에 전달하면, LLM은 도구를 인식하고 입력/출력 형식을 이해합니다.

여러 도구를 제공할 때는 항상 같은 포맷을 유지해야 합니다.

### 도구 설명 자동화

파이썬의 타입힌트, docstring, 함수명을 활용해 도구 설명을 자동 생성할 수 있습니다. 예시:

```python
@tool
def calculator(a: int, b: int) -> int:
    """두 정수를 곱합니다."""
    return a * b

print(calculator.to_string())
```

`@tool` 데코레이터를 사용하면, `to_string()`으로 도구 설명을 자동 추출할 수 있습니다.

### 범용 Tool 클래스 예시

```python
from typing import Callable

class Tool:
    def __init__(self, name: str, description: str, func: Callable, arguments: list, outputs: str):
        self.name = name
        self.description = description
        self.func = func
        self.arguments = arguments
        self.outputs = outputs

    def to_string(self) -> str:
        args_str = ", ".join([f"{arg_name}: {arg_type}" for arg_name, arg_type in self.arguments])
        return f"Tool Name: {self.name}, Description: {self.description}, Arguments: {args_str}, Outputs: {self.outputs}"

    def __call__(self, *args, **kwargs):
        return self.func(*args, **kwargs)
```

이 클래스를 활용하면 도구의 이름, 설명, 인자, 출력 등을 자동으로 관리할 수 있습니다.

`@tool` 데코레이터는 파이썬의 `inspect` 모듈로 함수 정보를 추출해 Tool 인스턴스를 만듭니다.

이렇게 만든 도구 설명은 시스템 프롬프트에 삽입되어 LLM이 활용할 수 있습니다.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/Agent_system_prompt_tools.png" alt="System prompt for tools"/>

[Actions](actions) 섹션에서 도구 호출 방법을 더 배웁니다.

### MCP(Model Context Protocol): 통합 도구 인터페이스

MCP는 **LLM에 도구를 제공하는 표준 오픈 프로토콜**입니다. MCP를 지원하는 프레임워크라면, 프로토콜 내 도구를 바로 활용할 수 있습니다.

자세한 내용은 [무료 MCP 코스](https://huggingface.co/learn/mcp-course/) 참고.

---

도구는 AI 에이전트의 능력을 크게 확장합니다.

정리:
- *도구란?*: LLM에 추가 능력을 부여하는 함수(계산, 외부 데이터 접근 등)
- *도구 정의법*: 명확한 설명, 입력/출력, 실행 함수 제공
- *도구의 중요성*: 정적 모델 한계를 극복, 실시간 작업/특화 행동 가능

이제 [에이전트 워크플로우](agent-steps-and-structure)로 넘어가, 에이전트가 어떻게 관찰·생각·행동하는지 살펴봅니다.

먼저, 짧은 퀴즈로 복습해봅시다! 